{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS6c0tGHqTU9l382LcnEU0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Regina-Arthur/Coding-Practice-Projects/blob/main/Pytorch_tutorial/RNN_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAuHkeEHk2ob",
        "outputId": "1c95b1f8-351a-4eb5-8edc-28d30a222f40"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/traffic_prediction_dataset/traffic.csv\")\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwrTRn-PrhL6",
        "outputId": "7d1472fa-9494-4244-fcc3-4d564b43bb5e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              DateTime  Junction  Vehicles           ID\n",
            "0  2015-11-01 00:00:00         1        15  20151101001\n",
            "1  2015-11-01 01:00:00         1        13  20151101011\n",
            "2  2015-11-01 02:00:00         1        10  20151101021\n",
            "3  2015-11-01 03:00:00         1         7  20151101031\n",
            "4  2015-11-01 04:00:00         1         9  20151101041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to datetime\n",
        "df['datetime'] = pd.to_datetime(df['DateTime'])\n",
        "\n",
        "# Extract day of week\n",
        "df['day_of_week'] = df['datetime'].dt.day_name()\n",
        "df['day_of_week_num'] = df['datetime'].dt.day_of_week\n",
        "\n",
        "# Extract time (hour and minute)\n",
        "df['hour'] = df['datetime'].dt.hour\n",
        "\n",
        "df['minute'] = df['datetime'].dt.minute\n",
        "\n",
        "\n",
        "# Optional: keep only those columns\n",
        "df = df[['day_of_week', 'day_of_week_num', 'hour', 'minute', 'Junction', 'Vehicles']]\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N6btYujqbfd",
        "outputId": "48f9c3cb-ea43-49f8-d87e-7d00ea8a0136"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  day_of_week  day_of_week_num  hour  minute  Junction  Vehicles\n",
            "0      Sunday                6     0       0         1        15\n",
            "1      Sunday                6     1       0         1        13\n",
            "2      Sunday                6     2       0         1        10\n",
            "3      Sunday                6     3       0         1         7\n",
            "4      Sunday                6     4       0         1         9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize hour\n",
        "mean =df['hour'].mean()\n",
        "std =df['hour'].std()\n",
        "df['hour_norm'] = (df['hour']- mean)/std\n",
        "\n",
        "mean =df['day_of_week_num'].mean()\n",
        "std =df['day_of_week_num'].std()\n",
        "df['day_of_week_num_norm'] = (df['day_of_week_num']- mean)/std\n",
        "\n",
        "mean =df['Vehicles'].mean()\n",
        "std =df['Vehicles'].std()\n",
        "df['vehicles_norm'] = (df['Vehicles']- mean)/std\n",
        "\n",
        "mean =df['Junction'].mean()\n",
        "std =df['Junction'].std()\n",
        "df['junction_norm'] = (df['Junction']- mean)/std\n",
        "\n",
        "# Optional: keep only those columns\n",
        "df = df[['day_of_week_num_norm', 'hour_norm', 'junction_norm', 'vehicles_norm']]\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8tNoLk0vHim",
        "outputId": "a8dab934-c34c-44f5-949d-91767fdd9445"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day_of_week_num_norm  hour_norm  junction_norm  vehicles_norm\n",
            "0              1.501982  -1.661308      -1.220893      -0.375485\n",
            "1              1.501982  -1.516846      -1.220893      -0.471870\n",
            "2              1.501982  -1.372384      -1.220893      -0.616448\n",
            "3              1.501982  -1.227923      -1.220893      -0.761026\n",
            "4              1.501982  -1.083461      -1.220893      -0.664641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Select features (inputs)\n",
        "features = ['day_of_week_num_norm', 'hour_norm', 'junction_norm', 'vehicles_norm']\n",
        "data = df[features].values.astype(np.float32)\n",
        "\n",
        "# Sequence length\n",
        "seq_len = 1\n",
        "X, y = [], []\n",
        "\n",
        "for i in range(len(data) - seq_len):\n",
        "    X.append(data[i:i+seq_len])\n",
        "    y.append(data[i+1: i+1+seq_len])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y).reshape(len(y),-1)\n",
        "\n",
        "print(X.shape, y.shape)  # e.g. (N, 24, 4), (N, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSGHZUcuvRt1",
        "outputId": "5b3007a7-f3f2-44e8-d013-ad62c5753199"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48119, 1, 4) (48119, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38mjGwyKC58l",
        "outputId": "f87cc209-4d8b-41ee-8394-f8e8fc3a9bc4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.5019825  -1.516846   -1.2208925  -0.4718701 ]\n",
            " [ 1.5019825  -1.3723844  -1.2208925  -0.616448  ]\n",
            " [ 1.5019825  -1.2279229  -1.2208925  -0.76102585]\n",
            " ...\n",
            " [ 0.5019908   1.3723844   1.8816291  -0.32729223]\n",
            " [ 0.5019908   1.516846    1.8816291  -0.03813647]\n",
            " [ 0.5019908   1.6613075   1.8816291  -0.52006274]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "X = torch.tensor(X)\n",
        "y = torch.tensor(y)\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "X_train = X[:40000]\n",
        "X_test = X[40001:]\n",
        "print(X_train.shape, X_test.shape)\n",
        "\n",
        "y_train = y[:40000]\n",
        "y_test = y[40001:]\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8furL0m8XZL",
        "outputId": "fe8b448b-708b-4eb3-cdb8-381be822acd4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([48119, 1, 4]) torch.Size([48119, 4])\n",
            "torch.Size([40000, 1, 4]) torch.Size([8118, 1, 4])\n",
            "torch.Size([40000, 4]) torch.Size([8118, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "kJHdnJukHzb2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TimeSeriesRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])  # take last time step output\n",
        "        return out\n",
        "\n",
        "model = TimeSeriesRNN(input_size=X.shape[2], hidden_size=64, num_layers=10, output_size=4)\n"
      ],
      "metadata": {
        "id": "I6Kf9HgWHrZ7"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC4g8-XKHixy",
        "outputId": "d99d8af5-db76-41db-9bce-38ea625ce658"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.0478\n",
            "Epoch 2, Loss: 0.0446\n",
            "Epoch 3, Loss: 0.0462\n",
            "Epoch 4, Loss: 0.0124\n",
            "Epoch 5, Loss: 0.0070\n",
            "Epoch 6, Loss: 0.0110\n",
            "Epoch 7, Loss: 0.0066\n",
            "Epoch 8, Loss: 0.0110\n",
            "Epoch 9, Loss: 0.0150\n",
            "Epoch 10, Loss: 0.0920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super().__init__()\n",
        "        self.GRU = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.norm = nn.LayerNorm(hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.GRU(x)\n",
        "        out = self.fc(out[:, -1, :])  # take last time step output\n",
        "        return out\n",
        "\n",
        "model = TimeSeriesGRU(input_size=X.shape[2], hidden_size=64, num_layers=10, output_size=4)\n"
      ],
      "metadata": {
        "id": "C6aen6CsIbrK"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRLsc75oItDq",
        "outputId": "8bd32f54-af0a-467c-ac53-a82156d6746d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.1532\n",
            "Epoch 2, Loss: 0.0872\n",
            "Epoch 3, Loss: 0.1173\n",
            "Epoch 4, Loss: 0.0710\n",
            "Epoch 5, Loss: 0.0425\n",
            "Epoch 6, Loss: 0.0226\n",
            "Epoch 7, Loss: 0.0184\n",
            "Epoch 8, Loss: 0.0096\n",
            "Epoch 9, Loss: 0.0080\n",
            "Epoch 10, Loss: 0.0320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # set to evaluation mode\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test).squeeze().cpu().numpy()\n",
        "    ground_truth = y_test.cpu().numpy()\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print(f\"Prediction: {predictions[i]} | Ground Truth: {ground_truth[i]}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gMPhJvRMezU",
        "outputId": "576f0f16-4db6-4dba-cee5-8cfcfa65e137"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [-1.033073    0.898086    0.866308   -0.18318078] | Ground Truth: [-0.9979966   0.9389999   0.8474552  -0.23090698]\n",
            "Prediction: [-1.0335131  1.0605503  0.8674403 -0.1104661] | Ground Truth: [-0.9979966  1.0834614  0.8474552 -0.4718701]\n",
            "Prediction: [-1.0339342   1.2450196   0.89373726 -0.2797938 ] | Ground Truth: [-0.9979966   1.2279229   0.8474552  -0.42367747]\n",
            "Prediction: [-1.0306605   1.4407966   0.90193266 -0.2709482 ] | Ground Truth: [-0.9979966   1.3723844   0.8474552  -0.18271434]\n",
            "Prediction: [-1.0022185  1.5188355  0.8862902 -0.1455847] | Ground Truth: [-0.9979966   1.516846    0.8474552  -0.52006274]\n",
            "Prediction: [-0.6130381   0.47600532  0.8734658  -0.43149278] | Ground Truth: [-0.9979966  1.6613075  0.8474552 -0.4718701]\n",
            "Prediction: [ 0.11223    -1.5659701   0.826046   -0.56976056] | Ground Truth: [-0.4980008  -1.6613075   0.8474552  -0.56825536]\n",
            "Prediction: [-0.6701043 -1.4443746  0.8170897 -0.6789016] | Ground Truth: [-0.4980008 -1.516846   0.8474552 -0.4718701]\n",
            "Prediction: [-0.64613855 -1.3936186   0.8275568  -0.6445569 ] | Ground Truth: [-0.4980008 -1.3723844  0.8474552 -0.616448 ]\n",
            "Prediction: [-0.66915286 -1.3034515   0.8256092  -0.682428  ] | Ground Truth: [-0.4980008 -1.2279229  0.8474552 -0.6646406]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super().__init__()\n",
        "        self.LSTM = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.LSTM(x)\n",
        "        out = self.fc(out[:, -1, :])  # take last time step output\n",
        "        return out\n",
        "\n",
        "model = TimeSeriesLSTM(input_size=X.shape[2], hidden_size=64, num_layers=1, output_size=4)\n"
      ],
      "metadata": {
        "id": "vXHP-WPWI4x3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_bL_cGWI7Cx",
        "outputId": "673b59c9-ab49-4ec1-c50f-ec30363d44a7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.1225\n",
            "Epoch 2, Loss: 0.1119\n",
            "Epoch 3, Loss: 0.0797\n",
            "Epoch 4, Loss: 0.0708\n",
            "Epoch 5, Loss: 0.0291\n",
            "Epoch 6, Loss: 0.1504\n",
            "Epoch 7, Loss: 0.0122\n",
            "Epoch 8, Loss: 0.0350\n",
            "Epoch 9, Loss: 0.0622\n",
            "Epoch 10, Loss: 0.0699\n"
          ]
        }
      ]
    }
  ]
}